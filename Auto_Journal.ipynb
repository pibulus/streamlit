{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+RteA4t0TjMgk9ixFv1D2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pibulus/streamlit/blob/main/Auto_Journal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is The Airtable Indexing Llamahub Function\n",
        "\n",
        "Steps to Follow:\n",
        "- Install Requests Library\n",
        "- First Set up OpenAI API Key\n",
        "- Set up Airtable API Key\n",
        "- Set up Airtable Base ID\n",
        "- Set up Airtable Table ID\n",
        "- Download Airtable Data\n",
        "- Index Airtable Data with LlamaIndex\n",
        "- Query Airtable Index\n"
      ],
      "metadata": {
        "id": "JTXxV5xk_Wxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests llama-index"
      ],
      "metadata": {
        "id": "fcoaPFVPCVk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e5db41-5a7c-4cae-ac55-72ec9f4884f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.6.32-py3-none-any.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.3/532.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Collecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchain>=0.0.154 (from llama-index)\n",
            "  Downloading langchain-0.0.214-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.2)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting typing-inspect==0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting typing-extensions==4.5.0 (from llama-index)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting tiktoken (from llama-index)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect==0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting langchainplus-sdk>=0.0.17 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (1.10.9)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, tiktoken, marshmallow-enum, aiosignal, openapi-schema-pydantic, langchainplus-sdk, dataclasses-json, aiohttp, openai, langchain, llama-index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 langchain-0.0.214 langchainplus-sdk-0.0.17 llama-index-0.6.32 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 tiktoken-0.4.0 typing-extensions-4.5.0 typing-inspect-0.8.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Insert your OpenAI API Key { display-mode: \"form\" }\n",
        "OPENAI_API_KEY = \"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\" #@param {type:\"string\"}\n",
        "#@title Insert your Airtable API Token { display-mode: \"form\" }\n",
        "Airtable_TOKEN = \"patwxpyQBLUG1jE9b.ff91312183072feea920aa9ecadda26673c818947430c503267ea2d7e62dc9fb\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "aP3qQi-2Ze9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f935f10c-31b3-4cad-9020-d40d4b77ba7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wPidzaEQEGuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sets up text-wrapping the output text for each cell\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "rw_MTOoCV19K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import langchain\n",
        "\n",
        "from llama_index import (\n",
        "    GPTVectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    download_loader,\n",
        "    GPTKeywordTableIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    LLMPredictor,\n",
        "    PromptHelper,\n",
        "    ServiceContext\n",
        ")\n",
        "from langchain import OpenAI\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "AirtableReader = download_loader('AirtableReader')\n",
        "reader = AirtableReader(Airtable_TOKEN)\n",
        "documents = reader.load_data(table_id=\"tblP6LQxyOo7JBiJC\",base_id=\"appUkRhauFCWrTrBd\")\n",
        "\n",
        "# define prompt helper\n",
        "# set maximum input size\n",
        "max_input_size = 4096\n",
        "# set number of output tokens\n",
        "num_output = 256\n",
        "# set maximum chunk overlap\n",
        "max_chunk_overlap = 20\n",
        "\n",
        "# define LLM\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.1, model_name=\"text-davinci-003\", max_tokens=num_output))\n",
        "\n",
        "# build index\n",
        "index = GPTVectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ra_wzR4FFS5M",
        "outputId": "0e3f1fd4-bf6b-4c4d-f259-b07cffa7c313"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "BEm1smKXDXPM",
        "outputId": "4bc51080-5645-41f5-bc0b-a68b7cde394a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Make sure to communicate openly and honestly with Mariana about your feelings and expectations.\n",
            "2. Show Mariana that you are serious about working on the relationship and being honest and authentic.\n",
            "3. Spend quality time together and get to know each other better.\n",
            "4. Respect Mariana's feelings and opinions, even if you don't agree with them.\n",
            "5. Show Mariana that you are committed to the relationship by taking steps to make it work, such as making plans for the future.\n",
            "6. Be supportive of Mariana and her goals and ambitions.\n",
            "7. Make sure to express your appreciation for Mariana and all that she does for you.\n",
            "8. Take time to do activities together that you both enjoy.\n",
            "9. Be patient and understanding with Mariana, even when things get difficult.\n",
            "10. Make sure to listen to Mariana and take her feelings into consideration.\n"
          ]
        }
      ]
    }
  ]
}